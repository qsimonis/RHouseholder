# This code provides artificial data for doing inference in the sparse CCA problem

require(rstiefel) # This will allow the easy generation of random rectangular orthogonal matrices via haar measure over the space of orthogonal matrices

require(mvtnorm) # This will be used for generating multivariate normal observations for our artificial datasets

# For the shared variation, I will generate the loading matrix via it's eigenvalue/svd decomposition
# by generating eigenvalues from the order statistics of a distribution with high mass near 0. This can
# be fulfilled from a gamma(1,2), gamma(2,2), or something similar.

# Generating the eigenvalues:

eigenvalue.simulator <- function(dims, alpha, beta){
  eigenvalues.simulated <- sort(-1/sort(-rgamma(dims, shape = alpha, rate = beta)), decreasing = T)
  return(eigenvalues.simulated)
}

# Note that eigenvalue.simulator will not necessarily produce a strong eigengap, instead, we will use the following function to create a produce a larger eigengap in our matrix.

# This function will return eigenvalues in the same way as eigenvalue.simulator, but will additionally
# push eigenvalues to a small value with probability "percent".

# What exactly will this small value be? It will be some number between 0 and the smallest eigenvalue
# generated. This will be done by multiplying our vector of eigenvalues with a vector generated by the
# following function:

# There are two inputs to this function:

# eigenvalue.list - a list of one of more vectors of eigenvalues sorted highest to lowest.
# percent - percent of eigenvalues to be shrunk towards 0.


# I think it would make more sense if eigenvalue.shrinker pushed only the smaller eigenvalues towards 0 to induce a more natural eigengap.

eigenvalue.simulator.sparse <- function(eigenvalues,percent){
  eigen.min <- min(eigenvalues)
  number.to.shrink <- floor(percent*length(eigenvalues))
  eigenvalues.shrunk <- eigenvalues
  eigenvalues.shrunk[(length(eigenvalues) - number.to.shrink): length(eigenvalues)] <- eigenvalues.shrunk[(length(eigenvalues) - number.to.shrink): length(eigenvalues)]*runif(1, min = 0, min(eigenvalues)/10)
  return(eigenvalues.shrunk)
}


# This will generate the final representation of the shared loading matrix for Bayesian CCA

shared.covariance.generator.eigen <- function(eigenvalues){
  Generated.orthogonal.matrix <-  rstiefel::rustiefel(m = length(eigenvalues), R = length(eigenvalues))
  Generated.covariance <- Generated.orthogonal.matrix%*%diag(eigenvalues)%*%t(Generated.orthogonal.matrix)
  return(Generated.covariance)
}



# We also need a way to generate the loading matrix of our data. I will propose generating our
# loading matrix with normal entries (with different covariance for each column), where the views
# will be generated with a bernoulli.

column.variance.generator <- function(view1.dim, view2.dim, variance.parameter1, variance.parameter2){
  column.variances <- rgamma(view1.dim + view2.dim, shape = variance.parameter1, rate = variance.parameter2)
}

view.specific.matrix.generator <- function(view1.dim, view2.dim, data1.dim, data2.dim,
                                           column.variances){
  print(dim(rstiefel::rustiefel(m = data1.dim, R = view1.dim)))
  print(dim(diag(column.variances[1:view1.dim])))
  view1.matrix <- (rstiefel::rustiefel(m = data1.dim, R = view1.dim)) %*% diag(column.variances[1:view1.dim])
  view2.matrix <- (rstiefel::rustiefel(m = data2.dim, R = view2.dim)) %*% diag(column.variances[(view1.dim + 1):
                                                                                             (view1.dim + view2.dim)])
  generated.matrix.1 <- cbind(view1.matrix, matrix(0,view2.dim, data1.dim))
  generated.matrix.1 <- cbind(matrix(0,view1.dim, data2.dim), view2.matrix)
  generated.matrix <- rbind(generated.matrix.1, generated.matrix.2)
    for(i in 1:(data1.dim + data2.dim)){
      if(i > data1.dim && j <= view1.dim){
        generated.matrix[i,j] = 0
      }
      else if(i <= data1.dim && j > view1.dim){
        generated.matrix[i,j] = 0
      }
    }
  return(generated.matrix)
  }

noise.covariance.generator <- function(data1.dim, data2.dim, shared.noise.1, shared.noise.2){
  covariance.noise <- matrix(0, nrow = data1.dim + data2.dim, ncol = data1.dim + data2.dim)
  noise.1 <- shared.noise.1
  noise.2 <- shared.noise.2
  for(i in 1:data1.dim){
    covariance.noise[i,i] <- noise.1
  }
  for(i in (data1.dim + 1):(data1.dim + data2.dim)){
    covariance.noise[i,i] <- noise.2
  }
  return(covariance.noise)
}


CCA.dataset.generator <- function(N.observations, data1.dim, data2.dim, view1.dim, view2.dim, shared.dim, shared.noise.1, shared.noise.2, alpha.eigenvalue, beta.eigenvalue,
                                  column.loading.variance.parameters, percent){
  Y <- matrix(0, nrow = data1.dim + data2.dim, ncol = N.observations)
  prior.generated.eigenvalues <- eigenvalue.simulator(dims = data1.dim + data2.dim, alpha = alpha.eigenvalue, beta = beta.eigenvalue)
  generated.eigenvalues <- eigenvalue.simulator.sparse(eigenvalues = prior.generated.eigenvalues,  percent = percent)
  shared.covariance <- shared.covariance.generator.eigen(generated.eigenvalues)
  noise.covariance <- noise.covariance.generator(data1.dim = data1.dim, data2.dim = data2.dim, shared.noise.1 = shared.noise.1, shared.noise.2 = shared.noise.2)
  view.loading.matrix <- view.specific.matrix.generator(view1.dim = view1.dim, view2.dim = view2.dim, data1.dim = data1.dim, data2.dim = data2.dim, variance.params = column.loading.variance.parameters)
  for(j in 1:N.observations){
    z <- rmvnorm(1, mean = rep(0, view1.dim + view2.dim), sigma = diag(view1.dim + view2.dim))
    Y[,j] <- t(rmvnorm(1, mean = view.loading.matrix%*%t(z), sigma = shared.covariance + noise.covariance))
  }
  generator.list <- list("eigenvalues" = generated.eigenvalues, "shared covariance" = shared.covariance, "noise covariance" = noise.covariance, "view loading matrix" = view.loading.matrix, "generated data" = Y)
  names(generator.list) <- c("eigenvalues", "shared covariance", "noise covariance", "view loading matrix", "generated data")
  return(generator.list)
}


ARD.dataset.generator <- function(N.observations, data1.dim, data2.dim, view1.dim, view2.dim, shared.dim, shared.noise.1, shared.noise.2, variance.parameter.1, variance.parameter.2, 
                                  percent){
  Y <- matrix(0, nrow = data1.dim + data2.dim, ncol = N.observations)
  generated.column.variances <- column.variance.generator(view1.dim = view1.dim, view2.dim = view2.dim, variance.parameter1 = variance.parameter.1, variance.parameter2 = variance.parameter.2 )
  shared.covariance <- diag(.1, data1.dim + data2.dim)
  noise.covariance <- 0
  view.loading.matrix <- view.specific.matrix.generator(view1.dim = view1.dim, view2.dim = view2.dim, data1.dim = data1.dim, data2.dim = data2.dim, column.variances = generated.column.variances)
  for(j in 1:N.observations){
    z <- rmvnorm(1, mean = rep(0, view1.dim + view2.dim), sigma = diag(view1.dim + view2.dim))
    Y[,j] <- t(rmvnorm(1, mean = view.loading.matrix%*%t(z), sigma = shared.covariance + noise.covariance))
  }
  generator.list <- list("column variances" = generated.column.variances,
                         "shared covariance" = shared.covariance,
                         "noise covariance" = noise.covariance,
                         "view loading matrix" = view.loading.matrix,
                         "generated data" = Y)
  
  names(generator.list) <- c("column variances", "shared covariance", "noise covariance",
                             "view loading matrix", "generated data")
  return(generator.list)
}

# An example line for generating the CCA dataset:

set.seed(1234)
X <- ARD.dataset.generator(N.observations = 200, data1.dim = 4, data2.dim = 3,
                      view1.dim = 1, view2.dim = 1, shared.dim = 6,
                      shared.noise.1 = .01, shared.noise.2 = .02,
                      variance.parameter.1 = 1, variance.parameter.2 = 1,
                      percent = .7)

simulation.ARD.data <- list(
  N = ncol(X[[5]]),
  D_1 = 4,
  D_2 = 3,
  K_1 = 1,
  K_2 = 1,
  D = nrow(X[[5]]),
  Q = 7,
  Y = t(X[[5]])
)

library(rstan)

ARD.initial.list <- list(
  column_view_lambda <- c(rep(x = .99, times = simulation.ARD.data[[4]]), rep(x = .01, times = simulation.ARD.data[[5]]))
)
names(ARD.initial.list) <- c("column_view_lambda")

ARD.inits <- list(ARD.initial.list)

names(ARD.inits) <- c("chain 1")

file.ARD.laptop <- "D:/School/Projects/GitMCMCHouseholder/RHouseholder/ARD prior test.stan"

fit.ARD.laptop <- stan(file = file.ARD.laptop, data = simulation.ARD.data,  iter = 15000, chains = 1, thin = 10)

summary(fit.ARD.laptop, pars = c("partial_matrix"))$summary

summary(fit.ARD.laptop, pars = c("column_tau"))$summary


# Use this when running on desktop

file.ARD.desktop <- "C:/Users/qsimo/Documents/Code/RHouseholder/ARD prior test.stan"

fit.ARD.desktop <- stan(file = file.ARD.desktop, data = simulation.ARD.data,  iter = 15000, chains = 1, thin = 10)

summary(fit.ARD.desktop, pars = c("partial_matrix"))$summary

summary(fit.ARD.desktop, pars = c("column_tau"))$summary

summary(fit.ARD.desktop, pars = c("X"))$summary

summary(fit.ARD.desktop, pars = c("B_1"))$summary




x <- seq(from = 0, to = 5, by = .01)


plot(x, dcauchy(x), type = "l")

abline(v = X$`column variances`)



CCA.dataset.generator(N.observations = 200, data1.dim = 5, data2.dim = 3,
                      view1.dim = 2, view2.dim = 2, shared.dim = 8,
                      shared.noise.1 = .01, shared.noise.2 = .02,
                      alpha.eigenvalue = 1, beta.eigenvalue = 1,
                      column.loading.variance.parameters = c(5,5),
                      percent = .7)


# Here I will begin the task of fitting the model from "Sparse Householder CCA" with Rstan:

library(rstan)

# This will be our first "true" data:


set.seed(1234)
Y <- CCA.dataset.generator(N.observations = 200, data1.dim = 11, data2.dim = 6,
                           view1.dim = 7, view2.dim = 3, shared.dim = 17,
                           shared.noise.1 = .01, shared.noise.2 = .02,
                           alpha.eigenvalue = 1, beta.eigenvalue = 1,
                           column.loading.variance.parameters = c(5,5),
                           percent = .7)
simulation.data <- list(
  N = ncol(Y[[5]]),
  D_1 = 11,
  D_2 = 6,
  K_1 = 7,
  K_2 = 3,
  D = nrow(Y[[5]]),
  Q = 17,
  Y = t(Y[[5]])
)


file.CCA <- "C:/Users/qsimo/Documents/Code/RHouseholder/Sparse householder CCA stuck.stan"



fit.CCA <- stan_model(file.CCA)


fit <- sampling(fit.CCA, data = simulation.data, chains = 1, iter = 10000, cores = parallel::detectCores())


print(fit)



file.CCA.laptop <- "D:/School/Projects/GitMCMCHouseholder/RHouseholder/Sparse householder CCA stuck.stan"

fit.CCA.laptop <- stan_model(file.CCA.laptop)

samples.CCA <- sampling(fit.CCA.laptop, data = simulation.data, chains = 1, iter = 300)

print(samples.CCA)



x <- seq(0,1, by = .01)

plot(x,dbeta(x, shape1 = .1, shape2 = .1), type = "l")


x.2 <- seq(0,4, by = .01)

plot(x.2,dexp(x.2, rate = 3.5), type = "l")
